{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import geopandas\n",
    "import argparse\n",
    "import glob\n",
    "import gpxpy\n",
    "import geojson\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from scipy.signal import medfilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "def rgb2hex(c):\n",
    "    hexc = '#%02x%02x%02x'%(int(c[0]*255), int(c[1]*255), int(c[2]*255))\n",
    "    return(hexc)\n",
    "\n",
    "def calc_dist_from_coords(p1, p2): # distance between p1 and p2 [lat,lon] (in deg)\n",
    "    lat1 = np.radians(p1[0])\n",
    "    lat2 = np.radians(p2[0])\n",
    "    lon1 = np.radians(p1[1])\n",
    "    lon2 = np.radians(p2[1])\n",
    "\n",
    "    delta_lat = lat2-lat1\n",
    "    delta_lon = lon2-lon1\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.power(np.sin(delta_lat/2.0), 2)+np.cos(lat1)*np.cos(lat2)*np.power(np.sin(delta_lon/2.0), 2)\n",
    "    c = 2.0*np.arctan2(np.sqrt(a), np.sqrt(1.0-a))\n",
    "\n",
    "    dist = 6371e3*c\n",
    "\n",
    "    return(dist)\n",
    "\n",
    "def calc_dist_from_coordsPoint2Line(p0, p1, p2): # distance from p0 to line defined by p1 and p2 [lat,lon] (in deg)\n",
    "    # Mercator projection\n",
    "    P0 = np.array([np.radians(p0[1]), np.arcsinh(np.tan(np.radians(p0[0])))])*6371e3\n",
    "    P1 = np.array([np.radians(p1[1]), np.arcsinh(np.tan(np.radians(p1[0])))])*6371e3\n",
    "    P2 = np.array([np.radians(p2[1]), np.arcsinh(np.tan(np.radians(p2[0])))])*6371e3\n",
    "\n",
    "    # distance from point to line\n",
    "    dist = abs((P2[1]-P1[1])*P0[0]-(P2[0]-P1[0])*P0[1]+P2[0]*P1[1]-P2[1]*P1[0])/np.sqrt(np.power(P2[1]-P1[1], 2)+np.power(P2[0]-P1[0], 2)) # (from https://en.wikipedia.org/wiki/Distance_from_a_point_to_a_line#Line_defined_by_two_points)\n",
    "\n",
    "    return(dist)\n",
    "\n",
    "def RDP(data, epsilon): # Ramer–Douglas–Peucker algorithm\n",
    "    if epsilon <= 0:\n",
    "        return(data)\n",
    "\n",
    "    dist_max = 0\n",
    "    index = 0\n",
    "\n",
    "    for i in np.arange(1, data.shape[0]):\n",
    "        dist = calc_dist_from_coordsPoint2Line(data[i, :2], data[0, :2], data[-1, :2]) # needs a 2D projection, does not work with cross-track distance\n",
    "\n",
    "        if dist > dist_max:\n",
    "            index = i\n",
    "            dist_max = dist\n",
    "\n",
    "    if dist_max > epsilon:\n",
    "        tmp1 = RDP(data[:index+1, :], epsilon)\n",
    "        tmp2 = RDP(data[index:, :], epsilon)\n",
    "\n",
    "        data_new = np.vstack((tmp1[:-1], tmp2))\n",
    "    else:\n",
    "        data_new = np.vstack((data[0, :], data[-1, :]))\n",
    "\n",
    "    return(data_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 19 files to process \n"
     ]
    }
   ],
   "source": [
    "data_input_raw = 'data_input_raw' \n",
    "data_processed_gpx = 'data_processed_gpx' \n",
    "data_geojson = 'data_geojson'\n",
    "visualize = False\n",
    "#SI_units = True\n",
    "\n",
    "dir_work = '/home/craigmatthewsmith/gps_tracks'\n",
    "os.chdir(dir_work)\n",
    "#os.getcwd()\n",
    "\n",
    "#gpx_file_temp = os.path.join(dir_work, 'data_input_gpx/Afternoon_Run55.gpx')\n",
    "#print(os.path.isfile(gpx_file_temp))\n",
    "\n",
    "ingest_file_list = glob.glob(os.path.join(data_input_raw, '*.gpx'))\n",
    "n_files = len(ingest_file_list)\n",
    "print('found %s files to process ' %(n_files))                              \n",
    "#print('found %s files' %(n_files))                              \n",
    "#geojson_file = os.path.join(data_geojson, '2020-03-22_15-06.geojson')\n",
    "#os.path.isfile(geojson_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  read 508 points \n",
      "  read 508 points \n",
      "  geojson_write_file is data_geojson/2020-03-15_22-30.geojson \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feature_collection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-afec7beef756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'  geojson_write_file is %s '\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeojson_write_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeojson_write_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mgeojson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_collection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# rename and archive gpx file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_collection' is not defined"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "#for f in range(0, n_files, 1):\n",
    "for f in range(0, 4, 1):\n",
    "    #print('  processing %s of % n_files ' %(f, n_files))                              \n",
    "    gpx_file_temp = ingest_file_list[f]\n",
    "\n",
    "    lat_lon_data = []\n",
    "    elevation_data = []\n",
    "    dt_data = []\n",
    "    timestamp_data = []\n",
    "\n",
    "    # read GPX file\n",
    "    with open(gpx_file_temp, 'r') as file:\n",
    "        gpx = gpxpy.parse(file)\n",
    "        for track in gpx.tracks:\n",
    "            for segment in track.segments:\n",
    "                for point in segment.points:\n",
    "                    lat_lon_data.append([point.latitude, point.longitude])\n",
    "                    elevation_data.append(point.elevation)\n",
    "                    timestamp_data.append(point.time.timestamp()) # convert time to timestamps (s)\n",
    "                    dt_data.append(point.time) # convert time to timestamps (s)\n",
    "\n",
    "    lat_lon_data   = np.array(lat_lon_data)  # [deg, deg]\n",
    "    elevation_data = np.array(elevation_data) # [m]\n",
    "    timestamp_data = np.array(timestamp_data) # [s]\n",
    "\n",
    "    n_points = len(timestamp_data)\n",
    "    print('  read %s points ' %(n_points))    \n",
    "    # calculate trackpoints distance, slope, speed and power\n",
    "    distance_data = np.zeros([n_points]) # [m]\n",
    "    slope_data    = np.zeros([n_points]) # [%]\n",
    "    speed_data    = np.zeros([n_points]) # [m/s]\n",
    "\n",
    "    for i in np.arange(1, n_points):\n",
    "        distance_data[i] = calc_dist_from_coords(lat_lon_data[i-1, :], lat_lon_data[i, :])\n",
    "        delta_elevation = elevation_data[i]-elevation_data[i-1]\n",
    "        if (distance_data[i] > 0):\n",
    "            slope_data[i] = delta_elevation/distance_data[i]\n",
    "        distance_data[i] = np.sqrt(np.power(distance_data[i], 2.0)+np.power(delta_elevation, 2.0)) # recalculate distance to take slope into account\n",
    "    for i in np.arange(1, timestamp_data.shape[0]):\n",
    "        if (timestamp_data[i] != timestamp_data[i-1]):\n",
    "            speed_data[i] = distance_data[i]/(timestamp_data[i]-timestamp_data[i-1])\n",
    "\n",
    "    # filter speed and slope data (default Strava filters)\n",
    "    slope_data = medfilt(slope_data, 5)\n",
    "    speed_data = medfilt(speed_data, 5)\n",
    "\n",
    "    n_points = len(slope_data)\n",
    "    print('  read %s points ' %(n_points))    \n",
    "    \n",
    "    use_RDP = True\n",
    "    # use Ramer–Douglas–Peucker algorithm to reduce the number of trackpoints\n",
    "    if use_RDP:\n",
    "        epsilon = 1 # [m]\n",
    "        tmp = np.hstack((lat_lon_data, np.arange(0, lat_lon_data.shape[0]).reshape((-1, 1)))) # hack\n",
    "        tmp_new = RDP(tmp, epsilon) # remove trackpoints less than epsilon meters away from the new track\n",
    "        index = tmp_new[:, 2].astype(int) # hack\n",
    "        lat_lon_data = lat_lon_data[index, :]\n",
    "        elevation_data = elevation_data[index]\n",
    "        timestamp_data = timestamp_data[index]\n",
    "        distance_data = distance_data[index]\n",
    "        slope_data = slope_data[index]\n",
    "        speed_data = speed_data[index]\n",
    "    slope_data = abs(slope_data*100) # decimal to %\n",
    "\n",
    "    n_points = len(slope_data)\n",
    "    print('  read %s points ' %(n_points))    \n",
    "    \n",
    "    # create GeoJSON feature collection\n",
    "    features = []\n",
    "    for i in np.arange(1, timestamp_data.shape[0]):\n",
    "        line = geojson.LineString([(lat_lon_data[i-1, 1], lat_lon_data[i-1, 0]), (lat_lon_data[i, 1], lat_lon_data[i, 0])]) # (lon,lat) to (lon,lat) format\n",
    "        features.append(feature)\n",
    "\n",
    "    feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "\n",
    "    \n",
    "    file_name = os.path.basename(gpx_file_temp.strip('.gpx'))\n",
    "    # write geojson file\n",
    "    geojson_write_file = gpx_file_temp.replace(file_name,dt_data[0].strftime('%Y-%m-%d_%H-%M')).replace(data_input_raw,data_geojson).replace('.gpx','.geojson')        \n",
    "    print('  geojson_write_file is %s ' %(geojson_write_file))\n",
    "    with open(geojson_write_file, 'w') as file:\n",
    "        geojson.dump(feature_collection, file)\n",
    "\n",
    "    # rename and archive gpx file \n",
    "    gpx_file_name_archive = gpx_file_temp.replace(file_name,dt_data[0].strftime('%Y-%m-%d_%H-%M')).replace(data_input_raw,data_processed_gpx)        \n",
    "    print('  gpx_file_name_archive is %s ' %(gpx_file_name_archive))\n",
    "    temp_command = 'mv -f '+gpx_file_temp+'_'+gpx_file_name_archive\n",
    "    print('  temp_command is %s ' %(temp_command))    \n",
    "    os.system(temp_command)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use_RDP = True\n",
    "# use Ramer–Douglas–Peucker algorithm to reduce the number of trackpoints\n",
    "if (use_RDP):\n",
    "    epsilon = 1 # [m]\n",
    "    tmp = np.hstack((lat_lon_data, np.arange(0, n_points).reshape((-1, 1)))) # hack\n",
    "    tmp_new = RDP(tmp, epsilon) # remove trackpoints less than epsilon meters away from the new track\n",
    "    index = tmp_new[:, 2].astype(int) # hack\n",
    "    lat_lon_data   = lat_lon_data  [index,:]\n",
    "    elevation_data = elevation_data[index]\n",
    "    timestamp_data = timestamp_data[index]\n",
    "    distance_data  = distance_data [index]\n",
    "    slope_data     = slope_data    [index]\n",
    "    speed_data     = speed_data    [index]\n",
    "\n",
    "n_points = len(slope_data)\n",
    "print('  read %s points ' %(n_points))    \n",
    "    \n",
    "# convert units\n",
    "if use_SI:\n",
    "    speed_data = speed_data*3.6 # m/s to km/h\n",
    "else:\n",
    "    speed_data = speed_data*2.236936 # m/s to mph\n",
    "\n",
    "slope_data = abs(slope_data*100) # decimal to %\n",
    "\n",
    "# create GeoJSON feature collection\n",
    "features = []\n",
    "for i in np.arange(1, n_points):\n",
    "    #print('    processing %s of %s points ' %(i, n_points))    \n",
    "    #print('    %s, %s, %s, %s ' %(lat_lon_data[i-1, 1], lat_lon_data[i-1, 0], lat_lon_data[i, 1], lat_lon_data[i, 0]))    \n",
    "    try:\n",
    "        line = geojson.LineString([(lat_lon_data[i-1, 1], lat_lon_data[i-1, 0]), (lat_lon_data[i, 1], lat_lon_data[i, 0])]) # (lon,lat) to (lon,lat) format\n",
    "        feature = geojson.Feature(geometry=line, properties = {'elevation': float('%.1f'%elevation_data[i]), 'slope': float('%.1f'%slope_data[i]), 'speed': float('%.1f'%speed_data[i])})\n",
    "        features.append(feature)\n",
    "    except:\n",
    "        print('    ERROR %s of %s points ' %(i, n_points))    \n",
    "\n",
    "feature_collection = geojson.FeatureCollection(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
