{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "from folium import plugins\n",
    "import geopandas\n",
    "import argparse\n",
    "import glob\n",
    "import gpxpy\n",
    "import geojson\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from scipy.signal import medfilt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# functions\n",
    "def rgb2hex(c):\n",
    "    hexc = '#%02x%02x%02x'%(int(c[0]*255), int(c[1]*255), int(c[2]*255))\n",
    "    return(hexc)\n",
    "\n",
    "def calc_dist_from_coords(p1, p2): # distance between p1 and p2 [lat,lon] (in deg)\n",
    "    lat1 = np.radians(p1[0])\n",
    "    lat2 = np.radians(p2[0])\n",
    "    lon1 = np.radians(p1[1])\n",
    "    lon2 = np.radians(p2[1])\n",
    "\n",
    "    delta_lat = lat2-lat1\n",
    "    delta_lon = lon2-lon1\n",
    "\n",
    "    # Haversine formula\n",
    "    a = np.power(np.sin(delta_lat/2.0), 2)+np.cos(lat1)*np.cos(lat2)*np.power(np.sin(delta_lon/2.0), 2)\n",
    "    c = 2.0*np.arctan2(np.sqrt(a), np.sqrt(1.0-a))\n",
    "\n",
    "    dist = 6371e3*c\n",
    "\n",
    "    return(dist)\n",
    "\n",
    "def calc_dist_from_coordsPoint2Line(p0, p1, p2): # distance from p0 to line defined by p1 and p2 [lat,lon] (in deg)\n",
    "    # Mercator projection\n",
    "    P0 = np.array([np.radians(p0[1]), np.arcsinh(np.tan(np.radians(p0[0])))])*6371e3\n",
    "    P1 = np.array([np.radians(p1[1]), np.arcsinh(np.tan(np.radians(p1[0])))])*6371e3\n",
    "    P2 = np.array([np.radians(p2[1]), np.arcsinh(np.tan(np.radians(p2[0])))])*6371e3\n",
    "\n",
    "    # distance from point to line\n",
    "    dist = abs((P2[1]-P1[1])*P0[0]-(P2[0]-P1[0])*P0[1]+P2[0]*P1[1]-P2[1]*P1[0])/np.sqrt(np.power(P2[1]-P1[1], 2)+np.power(P2[0]-P1[0], 2)) # (from https://en.wikipedia.org/wiki/Distance_from_a_point_to_a_line#Line_defined_by_two_points)\n",
    "\n",
    "    return(dist)\n",
    "\n",
    "def RDP(data, epsilon): # Ramer–Douglas–Peucker algorithm\n",
    "    if epsilon <= 0:\n",
    "        return(data)\n",
    "\n",
    "    dist_max = 0\n",
    "    index = 0\n",
    "\n",
    "    for i in np.arange(1, data.shape[0]):\n",
    "        dist = calc_dist_from_coordsPoint2Line(data[i, :2], data[0, :2], data[-1, :2]) # needs a 2D projection, does not work with cross-track distance\n",
    "\n",
    "        if dist > dist_max:\n",
    "            index = i\n",
    "            dist_max = dist\n",
    "\n",
    "    if dist_max > epsilon:\n",
    "        tmp1 = RDP(data[:index+1, :], epsilon)\n",
    "        tmp2 = RDP(data[index:, :], epsilon)\n",
    "\n",
    "        data_new = np.vstack((tmp1[:-1], tmp2))\n",
    "    else:\n",
    "        data_new = np.vstack((data[0, :], data[-1, :]))\n",
    "\n",
    "    return(data_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 33 files to process \n"
     ]
    }
   ],
   "source": [
    "data_input_raw = 'data_input_raw' \n",
    "data_processed_gpx = 'data_processed_gpx' \n",
    "data_geojson = 'data_geojson'\n",
    "visualize = False\n",
    "#SI_units = True\n",
    "\n",
    "dir_work = '/home/craigmatthewsmith/gps_tracks'\n",
    "os.chdir(dir_work)\n",
    "#os.getcwd()\n",
    "\n",
    "#gpx_file_temp = os.path.join(dir_work, 'data_input_gpx/Afternoon_Run55.gpx')\n",
    "#print(os.path.isfile(gpx_file_temp))\n",
    "\n",
    "ingest_file_list = glob.glob(os.path.join(data_input_raw, '*.gpx'))\n",
    "n_files = len(ingest_file_list)\n",
    "print('found %s files to process ' %(n_files))                              \n",
    "#print('found %s files' %(n_files))                              \n",
    "#geojson_file = os.path.join(data_geojson, '2020-03-22_15-06.geojson')\n",
    "#os.path.isfile(geojson_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  read 0 points \n",
      "  read 0 points \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-28d814a6aea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_RDP\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;31m# [m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlat_lon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat_lon_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# hack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mtmp_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRDP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove trackpoints less than epsilon meters away from the new track\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# hack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/env_gis/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;31m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "#for f in range(0, n_files, 1):\n",
    "for f in range(0, 4, 1):\n",
    "    #print('  processing %s of % n_files ' %(f, n_files))                              \n",
    "    gpx_file_temp = ingest_file_list[f]\n",
    "\n",
    "    lat_lon_data = []\n",
    "    elevation_data = []\n",
    "    dt_data = []\n",
    "    timestamp_data = []\n",
    "\n",
    "    # read GPX file\n",
    "    with open(gpx_file_temp, 'r') as file:\n",
    "        gpx = gpxpy.parse(file)\n",
    "        for track in gpx.tracks:\n",
    "            for segment in track.segments:\n",
    "                for point in segment.points:\n",
    "                    lat_lon_data.append([point.latitude, point.longitude])\n",
    "                    elevation_data.append(point.elevation)\n",
    "                    timestamp_data.append(point.time.timestamp()) # convert time to timestamps (s)\n",
    "                    dt_data.append(point.time) # convert time to timestamps (s)\n",
    "\n",
    "    lat_lon_data   = np.array(lat_lon_data)  # [deg, deg]\n",
    "    elevation_data = np.array(elevation_data) # [m]\n",
    "    timestamp_data = np.array(timestamp_data) # [s]\n",
    "\n",
    "    n_points = len(timestamp_data)\n",
    "    print('  read %s points ' %(n_points))    \n",
    "    # calculate trackpoints distance, slope, speed and power\n",
    "    distance_data = np.zeros([n_points]) # [m]\n",
    "    slope_data    = np.zeros([n_points]) # [%]\n",
    "    speed_data    = np.zeros([n_points]) # [m/s]\n",
    "\n",
    "    for i in np.arange(1, n_points):\n",
    "        distance_data[i] = calc_dist_from_coords(lat_lon_data[i-1, :], lat_lon_data[i, :])\n",
    "        delta_elevation = elevation_data[i]-elevation_data[i-1]\n",
    "        if (distance_data[i] > 0):\n",
    "            slope_data[i] = delta_elevation/distance_data[i]\n",
    "        distance_data[i] = np.sqrt(np.power(distance_data[i], 2.0)+np.power(delta_elevation, 2.0)) # recalculate distance to take slope into account\n",
    "    for i in np.arange(1, timestamp_data.shape[0]):\n",
    "        if (timestamp_data[i] != timestamp_data[i-1]):\n",
    "            speed_data[i] = distance_data[i]/(timestamp_data[i]-timestamp_data[i-1])\n",
    "\n",
    "    # filter speed and slope data (default Strava filters)\n",
    "    slope_data = medfilt(slope_data, 5)\n",
    "    speed_data = medfilt(speed_data, 5)\n",
    "\n",
    "    n_points = len(slope_data)\n",
    "    print('  read %s points ' %(n_points))    \n",
    "    \n",
    "    use_RDP = True\n",
    "    # use Ramer–Douglas–Peucker algorithm to reduce the number of trackpoints\n",
    "    if use_RDP:\n",
    "        epsilon = 1 # [m]\n",
    "        tmp = np.hstack((lat_lon_data, np.arange(0, lat_lon_data.shape[0]).reshape((-1, 1)))) # hack\n",
    "        tmp_new = RDP(tmp, epsilon) # remove trackpoints less than epsilon meters away from the new track\n",
    "        index = tmp_new[:, 2].astype(int) # hack\n",
    "        lat_lon_data = lat_lon_data[index, :]\n",
    "        elevation_data = elevation_data[index]\n",
    "        timestamp_data = timestamp_data[index]\n",
    "        distance_data = distance_data[index]\n",
    "        slope_data = slope_data[index]\n",
    "        speed_data = speed_data[index]\n",
    "    slope_data = abs(slope_data*100) # decimal to %\n",
    "\n",
    "    n_points = len(slope_data)\n",
    "    print('  read %s points ' %(n_points))    \n",
    "    \n",
    "    # create GeoJSON feature collection\n",
    "    features = []\n",
    "    for i in np.arange(1, n_points):\n",
    "        line = geojson.LineString([(lat_lon_data[i-1, 1], lat_lon_data[i-1, 0]), (lat_lon_data[i, 1], lat_lon_data[i, 0])]) # (lon,lat) to (lon,lat) format\n",
    "        feature = geojson.Feature(geometry=line, properties={'elevation': float('%.1f'%elevation_data[i]), 'slope': float('%.1f'%slope_data[i]), 'speed': float('%.1f'%speed_data[i])})\n",
    "        features.append(feature)\n",
    "\n",
    "    feature_collection = geojson.FeatureCollection(features)\n",
    "\n",
    "    file_name = os.path.basename(gpx_file_temp.strip('.gpx'))\n",
    "    # write geojson file\n",
    "    geojson_write_file = gpx_file_temp.replace(file_name,dt_data[0].strftime('%Y-%m-%d_%H-%M')).replace(data_input_raw,data_geojson).replace('.gpx','.geojson')        \n",
    "    print('  geojson_write_file is %s ' %(geojson_write_file))\n",
    "    with open(geojson_write_file, 'w') as file:\n",
    "        geojson.dump(feature_collection, file)\n",
    "\n",
    "    # rename and archive gpx file \n",
    "    gpx_file_name_archive = gpx_file_temp.replace(file_name,dt_data[0].strftime('%Y-%m-%d_%H-%M')).replace(data_input_raw,data_processed_gpx)        \n",
    "    print('  gpx_file_name_archive is %s ' %(gpx_file_name_archive))\n",
    "    if (' ' in gpx_file_temp):\n",
    "        temp_command = 'mv -f \"'+gpx_file_temp+'\" '+gpx_file_name_archive\n",
    "    else:\n",
    "        temp_command = 'mv -f '+gpx_file_temp+' '+gpx_file_name_archive\n",
    "\n",
    "    print('  temp_command is %s ' %(temp_command))    \n",
    "    os.system(temp_command)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use_RDP = True\n",
    "# use Ramer–Douglas–Peucker algorithm to reduce the number of trackpoints\n",
    "if (use_RDP):\n",
    "    epsilon = 1 # [m]\n",
    "    tmp = np.hstack((lat_lon_data, np.arange(0, n_points).reshape((-1, 1)))) # hack\n",
    "    tmp_new = RDP(tmp, epsilon) # remove trackpoints less than epsilon meters away from the new track\n",
    "    index = tmp_new[:, 2].astype(int) # hack\n",
    "    lat_lon_data   = lat_lon_data  [index,:]\n",
    "    elevation_data = elevation_data[index]\n",
    "    timestamp_data = timestamp_data[index]\n",
    "    distance_data  = distance_data [index]\n",
    "    slope_data     = slope_data    [index]\n",
    "    speed_data     = speed_data    [index]\n",
    "\n",
    "n_points = len(slope_data)\n",
    "print('  read %s points ' %(n_points))    \n",
    "    \n",
    "# convert units\n",
    "if use_SI:\n",
    "    speed_data = speed_data*3.6 # m/s to km/h\n",
    "else:\n",
    "    speed_data = speed_data*2.236936 # m/s to mph\n",
    "\n",
    "slope_data = abs(slope_data*100) # decimal to %\n",
    "\n",
    "# create GeoJSON feature collection\n",
    "features = []\n",
    "for i in np.arange(1, n_points):\n",
    "    #print('    processing %s of %s points ' %(i, n_points))    \n",
    "    #print('    %s, %s, %s, %s ' %(lat_lon_data[i-1, 1], lat_lon_data[i-1, 0], lat_lon_data[i, 1], lat_lon_data[i, 0]))    \n",
    "    try:\n",
    "        line = geojson.LineString([(lat_lon_data[i-1, 1], lat_lon_data[i-1, 0]), (lat_lon_data[i, 1], lat_lon_data[i, 0])]) # (lon,lat) to (lon,lat) format\n",
    "        feature = geojson.Feature(geometry=line, properties = {'elevation': float('%.1f'%elevation_data[i]), 'slope': float('%.1f'%slope_data[i]), 'speed': float('%.1f'%speed_data[i])})\n",
    "        features.append(feature)\n",
    "    except:\n",
    "        print('    ERROR %s of %s points ' %(i, n_points))    \n",
    "\n",
    "feature_collection = geojson.FeatureCollection(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_input_raw/Afternoon_Run (1).gpx\n"
     ]
    }
   ],
   "source": [
    "f = 0\n",
    "\n",
    "gpx_file_temp = ingest_file_list[f]\n",
    "print(gpx_file_temp)\n",
    "lat_lon_data = []\n",
    "elevation_data = []\n",
    "dt_data = []\n",
    "timestamp_data = []\n",
    "\n",
    "# read GPX file\n",
    "with open(gpx_file_temp, 'r') as file:\n",
    "    gpx = gpxpy.parse(file)\n",
    "    for track in gpx.tracks:\n",
    "        for segment in track.segments:\n",
    "            for point in segment.points:\n",
    "                lat_lon_data.append([point.latitude, point.longitude])\n",
    "                elevation_data.append(point.elevation)\n",
    "                timestamp_data.append(point.time.timestamp()) # convert time to timestamps (s)\n",
    "                dt_data.append(point.time) # convert time to timestamps (s)\n",
    "\n",
    "lat_lon_data   = np.array(lat_lon_data)  # [deg, deg]\n",
    "elevation_data = np.array(elevation_data) # [m]\n",
    "timestamp_data = np.array(timestamp_data) # [s]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(lat_lon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  read 0 points \n",
      "  read 0 points \n"
     ]
    }
   ],
   "source": [
    "n_points = len(timestamp_data)\n",
    "print('  read %s points ' %(n_points))    \n",
    "# calculate trackpoints distance, slope, speed and power\n",
    "distance_data = np.zeros([n_points]) # [m]\n",
    "slope_data    = np.zeros([n_points]) # [%]\n",
    "speed_data    = np.zeros([n_points]) # [m/s]\n",
    "\n",
    "for i in np.arange(1, n_points):\n",
    "    distance_data[i] = calc_dist_from_coords(lat_lon_data[i-1, :], lat_lon_data[i, :])\n",
    "    delta_elevation = elevation_data[i]-elevation_data[i-1]\n",
    "    if (distance_data[i] > 0):\n",
    "        slope_data[i] = delta_elevation/distance_data[i]\n",
    "    distance_data[i] = np.sqrt(np.power(distance_data[i], 2.0)+np.power(delta_elevation, 2.0)) # recalculate distance to take slope into account\n",
    "for i in np.arange(1, timestamp_data.shape[0]):\n",
    "    if (timestamp_data[i] != timestamp_data[i-1]):\n",
    "        speed_data[i] = distance_data[i]/(timestamp_data[i]-timestamp_data[i-1])\n",
    "\n",
    "# filter speed and slope data (default Strava filters)\n",
    "slope_data = medfilt(slope_data, 5)\n",
    "speed_data = medfilt(speed_data, 5)\n",
    "\n",
    "n_points = len(slope_data)\n",
    "print('  read %s points ' %(n_points))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_RDP = True\n",
    "# use Ramer–Douglas–Peucker algorithm to reduce the number of trackpoints\n",
    "if use_RDP:\n",
    "    epsilon = 1 # [m]\n",
    "    tmp = np.hstack((lat_lon_data, np.arange(0, lat_lon_data.shape[0]).reshape((-1, 1)))) # hack\n",
    "    tmp_new = RDP(tmp, epsilon) # remove trackpoints less than epsilon meters away from the new track\n",
    "    index = tmp_new[:, 2].astype(int) # hack\n",
    "    lat_lon_data = lat_lon_data[index, :]\n",
    "    elevation_data = elevation_data[index]\n",
    "    timestamp_data = timestamp_data[index]\n",
    "    distance_data = distance_data[index]\n",
    "    slope_data = slope_data[index]\n",
    "    speed_data = speed_data[index]\n",
    "slope_data = abs(slope_data*100) # decimal to %\n",
    "\n",
    "n_points = len(slope_data)\n",
    "print('  read %s points ' %(n_points))    \n",
    "\n",
    "# create GeoJSON feature collection\n",
    "features = []\n",
    "for i in np.arange(1, n_points):\n",
    "    line = geojson.LineString([(lat_lon_data[i-1, 1], lat_lon_data[i-1, 0]), (lat_lon_data[i, 1], lat_lon_data[i, 0])]) # (lon,lat) to (lon,lat) format\n",
    "    feature = geojson.Feature(geometry=line, properties={'elevation': float('%.1f'%elevation_data[i]), 'slope': float('%.1f'%slope_data[i]), 'speed': float('%.1f'%speed_data[i])})\n",
    "    features.append(feature)\n",
    "\n",
    "feature_collection = geojson.FeatureCollection(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afternoon_Run (1)\n"
     ]
    }
   ],
   "source": [
    "file_name = os.path.basename(gpx_file_temp.strip('.gpx'))\n",
    "print(file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  geojson_write_file is data_geojson/2020-02-02_00-37.geojson \n"
     ]
    }
   ],
   "source": [
    "# write geojson file\n",
    "geojson_write_file = gpx_file_temp.replace(file_name,dt_data[0].strftime('%Y-%m-%d_%H-%M')).replace(data_input_raw,data_geojson).replace('.gpx','.geojson')        \n",
    "print('  geojson_write_file is %s ' %(geojson_write_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(geojson_write_file, 'w') as file:\n",
    "    geojson.dump(feature_collection, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  gpx_file_name_archive is data_processed_gpx/2020-02-02_00-37.gpx \n"
     ]
    }
   ],
   "source": [
    "# rename and archive gpx file \n",
    "gpx_file_name_archive = gpx_file_temp.replace(file_name,dt_data[0].strftime('%Y-%m-%d_%H-%M')).replace(data_input_raw,data_processed_gpx)        \n",
    "print('  gpx_file_name_archive is %s ' %(gpx_file_name_archive))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' ' in gpx_file_temp\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  temp_command is mv -f \"data_input_raw/Afternoon_Run (1).gpx\" data_processed_gpx/2020-02-02_00-37.gpx \n"
     ]
    }
   ],
   "source": [
    "temp_command = 'mv -f \"'+gpx_file_temp+'\" '+gpx_file_name_archive\n",
    "print('  temp_command is %s ' %(temp_command))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(temp_command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
